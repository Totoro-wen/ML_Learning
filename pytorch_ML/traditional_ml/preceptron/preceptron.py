# envs:# CPython 3.6.8# IPython 7.2.0# torch 1.0.0# Task: implementation of the classic Perception for binary classification(here:0/1 classs labels)# 二分类线性分类模型，其输入为实例的特征向量，输出为实例的类别，取+1或者-1值。# 简单来说，就是在平面坐标轴画一条直线，把点分为两类。# -*- coding:utf-8 -*-import numpy as npimport matplotlib.pyplot as plt # inlineimport torch############################1. prepare datasetdata = np.genfromtxt('../data/preception_toydata.txt', delimiter='\t')# 转义字符:\\(反斜杠-可以打印出一个反斜杠)# 转义字符:\'（单引号-可以打印出一个单引号）# 转义字符:\"(双引号-可以打印出一个双引号)# 转义字符:\a(响铃-用于触发系统蜂鸣器)# 转义字符:\n(换行符-将光标移动到下一行的开头)# 转义字符:\t(水平制表符-将光标向右移动一个制表符位)# data[:, :2] 取数据的所有行,前两列X, y = data[:, :2], data[:, 2]# type 获取数据类型# dtype 数组元素的类型# astype 修改数据类型y = y.astype(np.int)print('Class label counts:', np.bincount(y))# np.bincount()索引值在y中出现的次数# 我们可以看到x中最大的数为7，因此bin的数量为8，那么它的索引值为0->7# x = np.array([0, 1, 1, 3, 2, 1, 7])# 索引0出现了1次，索引1出现了3次, 索引2出现了1次, 索引3出现了1次, 索引4出现了0次, 索引5出现了0次,索引6出现了0次, 索引7出现了1次# np.bincount(x)# 因此，输出结果为：array([1, 3, 1, 1, 0, 0, 0, 1])print('X.shape:', X.shape)print('y.shape:', y.shape)# shuffling & training/test splitshuffle_idx = np.arange(y.shape[0])shuffle_rng = np.random.RandomState(123)# 使用RandomState获得随机数生成器shuffle_rng.shuffle(shuffle_idx)X, y = X[shuffle_idx], y[shuffle_idx]X_train, X_test = X[shuffle_idx[:70]], X[shuffle_idx[70:]]y_train, y_test = y[shuffle_idx[:70]], y[shuffle_idx[70:]]# normalize (mean zero, unit variance)mu, sigma = X_train.mean(axis=0), X_train.std(axis=0)X_train = (X_train - mu) / sigmaX_test = (X_test - mu) / sigmaplt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker = 'o')plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker = 's')plt.xlabel('feature1')plt.ylabel('feature2')plt.legend()# 显示图标!plt.show()######################################2. Defining the Perception modeldevice = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# print('device:', device)def custom_where(cond, x_1, x_2):    cond = cond.float()    return (cond * x_1) + ((1 - cond) * x_2)## 注意bool tensor(conda) 不能直接进行运算,需要对其转换数据类型# 在python中，以下数值会被认为是False：#     为0的数字，包括0，0.0#     空字符串，包括”，”“#     表示空值的None#     空集合，包括()，[]，{}# 其他的值都认为是True。## None是python中的一个特殊值，表示什么都没有，它和0、空字符、False、空集合都不一样。# bool(‘False’)的结果是True，因为‘False’是一个不为空的字符串，当被转换成bool类型之后，就得到True。# bool(’ ‘)的结果是True，一个空格也不能算作空字符串。# bool(”)才是False。class Perceptron():    def __init__(self, num_features):        self.num_features = num_features        self.weights = torch.zeros(num_features, 1,                                   dtype=torch.float32, device=device)        self.bias = torch.zeros(1, dtype=torch.float32, device=device)    def forward(self, x):        linear = torch.add(torch.mm(x, self.weights), self.bias)        # print('linear:', linear)        predictions = custom_where(linear > 0., 1, 0).float()        return predictions    def backward(self, x, y):        predictions = self.forward(x)        errors = y - predictions        return errors    def train(self, x, y, epochs):        for e in range(epochs):            for i in range(y.size()[0]):                # use view because backward expects a matrix (i.e., 2D tensor)                errors = self.backward(x[i].view(1, self.num_features), y[i]).view(-1)                # print(errors.dtype())                self.weights += (errors * x[i]).view(self.num_features, 1)                self.bias += errors    def evaluate(self, x, y):        predictions = self.forward(x).view(-1)        accuracy = torch.sum(predictions == y).float() / y.size()[0]        return accuracy################################3.Training the Perceptionppn = Perceptron(num_features=2)X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)ppn.train(X_train_tensor, y_train_tensor, epochs=5)print('model parameters:')print('     weights:%s'% ppn.weights)print('     bias:%s'% ppn.bias)###############################4.Evaluating the modelX_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)test_acc = ppn.evaluate(X_test_tensor, y_test_tensor)print('Test set accuary: %.2f%%'% (test_acc))#Test set accuary: 0.93%##############################5.2D Decision Boundaryw, b = ppn.weights, ppn.biasx_min = -2y_min = ( (-(w[0]) * x_min) - b[0]) / w[1]x_max = -2y_max = ( (-(w[0]) * x_max) - b[0]) / w[1]# 子图的行列数, 所有子图共享X轴或Y轴,figsize为图像大小fig, ax = plt.subplots(1, 2, sharex=True, figsize=(7,3))ax[0].plot([x_min, x_max], [y_min, y_max])ax[1].plot([x_min, x_max], [y_min, y_max])ax[0].scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker='o')ax[0].scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker='s')ax[1].scatter(X_test[y_test==0, 0], X_test[y_test==0, 1], label='class 0', marker='o')ax[1].scatter(X_test[y_test==1, 0], X_test[y_test==1, 1], label='class 1', marker='s')ax[1].legend(loc='upper left')plt.show()